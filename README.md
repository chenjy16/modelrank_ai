# ModelRank AI ğŸ†

This is an automatically updated open-source large language model leaderboard with data sourced from HuggingFace. Through this project, you can easily view and compare the performance of various large language models.

## Project Features

- ğŸ”„ **Automatic Updates**: Automatically fetches the latest model evaluation data from HuggingFace daily via GitHub Actions
- ğŸ“Š **Complete Data**: Provides comprehensive leaderboard data, including model names, parameter counts, and various evaluation scores
- ğŸ“± **Responsive Design**: Supports viewing leaderboard data on various devices
- ğŸ” **Search and Sort**: Supports searching and sorting by different metrics on the complete leaderboard page
- ğŸ“¥ **Data Download**: Provides data in JSON and CSV formats for download

## ğŸ† ModelRank AI Leaderboard

*Last updated: 2025-04-07 06:36:11 UTC*

| Rank | Model | Avg | Params(B) | IFEval | BBH | MATH | GPQA | MUSR | MMLU-PRO |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-3.2-instruct-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-3.2-instruct-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-3.2-instruct-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-3.2-instruct-78b) | 52.08 | 78.0 | 80.63 | 62.61 | 40.33 | 20.36 | 38.53 | 70.03 |
| 2 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-3.1-instruct-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-3.1-instruct-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-3.1-instruct-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-3.1-instruct-78b) | 51.29 | 78.0 | 81.36 | 62.41 | 39.27 | 19.46 | 36.50 | 68.72 |
| 3 | [<a target="_blank" href="https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">dfurman/CalmeRys-78B-Orpo-v0.1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/dfurman__CalmeRys-78B-Orpo-v0.1-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1) | 51.23 | 78.0 | 81.63 | 61.92 | 40.63 | 20.02 | 36.37 | 66.80 |
| 4 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.4-rys-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.4-rys-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b) | 50.77 | 78.0 | 80.11 | 62.16 | 40.71 | 20.36 | 34.57 | 66.69 |
| 5 | [<a target="_blank" href="https://huggingface.co/huihui-ai/Qwen2.5-72B-Instruct-abliterated" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">huihui-ai/Qwen2.5-72B-Instruct-abliterated</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/huihui-ai__Qwen2.5-72B-Instruct-abliterated-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/huihui-ai/Qwen2.5-72B-Instruct-abliterated) | 48.11 | 72.7 | 85.93 | 60.49 | 60.12 | 19.35 | 12.34 | 50.41 |
| 6 | [<a target="_blank" href="https://huggingface.co/Qwen/Qwen2.5-72B-Instruct" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Qwen/Qwen2.5-72B-Instruct</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-72B-Instruct-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) | 47.98 | 72.7 | 86.38 | 61.87 | 59.82 | 16.67 | 11.74 | 51.40 |
| 7 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2.5-72b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.1-qwen2.5-72b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-qwen2.5-72b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2.5-72b) | 47.86 | 72.7 | 86.62 | 61.66 | 59.14 | 15.10 | 13.30 | 51.32 |
| 8 | [<a target="_blank" href="https://huggingface.co/newsbang/Homer-v1.0-Qwen2.5-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">newsbang/Homer-v1.0-Qwen2.5-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/newsbang__Homer-v1.0-Qwen2.5-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/newsbang/Homer-v1.0-Qwen2.5-72B) | 47.46 | 72.7 | 76.28 | 62.27 | 49.02 | 22.15 | 17.90 | 57.17 |
| 9 | [<a target="_blank" href="https://huggingface.co/ehristoforu/qwen2.5-test-32b-it" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ehristoforu/qwen2.5-test-32b-it</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/ehristoforu__qwen2.5-test-32b-it-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/ehristoforu/qwen2.5-test-32b-it) | 47.37 | 32.8 | 78.89 | 58.28 | 59.74 | 15.21 | 19.13 | 52.95 |
| 10 | [<a target="_blank" href="https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Saxo__Linkbricks-Horizon-AI-Avengers-V1-32B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B) | 47.34 | 32.8 | 79.72 | 57.63 | 60.27 | 14.99 | 18.16 | 53.25 |
| 11 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2.5-72b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.2-qwen2.5-72b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-qwen2.5-72b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2.5-72b) | 47.22 | 72.7 | 84.77 | 61.80 | 58.91 | 14.54 | 12.02 | 51.31 |
| 12 | [<a target="_blank" href="https://huggingface.co/fluently-lm/FluentlyLM-Prinum" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">fluently-lm/FluentlyLM-Prinum</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/fluently-lm__FluentlyLM-Prinum-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/fluently-lm/FluentlyLM-Prinum) | 47.22 | 32.8 | 80.90 | 59.48 | 54.00 | 18.23 | 17.26 | 53.42 |
| 13 | [<a target="_blank" href="https://huggingface.co/JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/JungZoona__T3Q-Qwen2.5-14B-Instruct-1M-e3-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3) | 47.09 | 0 | 73.24 | 65.47 | 28.63 | 22.26 | 38.69 | 54.27 |
| 14 | [<a target="_blank" href="https://huggingface.co/JungZoona/T3Q-qwen2.5-14b-v1.0-e3" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">JungZoona/T3Q-qwen2.5-14b-v1.0-e3</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/JungZoona__T3Q-qwen2.5-14b-v1.0-e3-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/JungZoona/T3Q-qwen2.5-14b-v1.0-e3) | 47.09 | 14.8 | 73.24 | 65.47 | 28.63 | 22.26 | 38.69 | 54.27 |
| 15 | [<a target="_blank" href="https://huggingface.co/zetasepic/Qwen2.5-32B-Instruct-abliterated-v2" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">zetasepic/Qwen2.5-32B-Instruct-abliterated-v2</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/zetasepic__Qwen2.5-32B-Instruct-abliterated-v2-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/zetasepic/Qwen2.5-32B-Instruct-abliterated-v2) | 46.89 | 32.8 | 83.34 | 56.53 | 59.52 | 15.66 | 14.93 | 51.35 |
| 16 | [<a target="_blank" href="https://huggingface.co/rubenroy/Gilgamesh-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rubenroy/Gilgamesh-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/rubenroy__Gilgamesh-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/rubenroy/Gilgamesh-72B) | 46.79 | 72.7 | 84.86 | 61.84 | 43.81 | 19.24 | 17.66 | 53.36 |
| 17 | [<a target="_blank" href="https://huggingface.co/Sakalti/ultiima-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Sakalti/ultiima-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Sakalti__ultiima-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Sakalti/ultiima-72B) | 46.77 | 72.7 | 71.40 | 61.10 | 53.55 | 21.92 | 18.12 | 54.51 |
| 18 | [<a target="_blank" href="https://huggingface.co/CombinHorizon/zetasepic-abliteratedV2-Qwen2.5-32B-Inst-BaseMerge-TIES" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">CombinHorizon/zetasepic-abliteratedV2-Qwen2.5-32B-Inst-BaseMerge-TIES</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/CombinHorizon__zetasepic-abliteratedV2-Qwen2.5-32B-Inst-BaseMerge-TIES-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/CombinHorizon/zetasepic-abliteratedV2-Qwen2.5-32B-Inst-BaseMerge-TIES) | 46.76 | 32.8 | 83.28 | 56.83 | 58.53 | 15.66 | 14.22 | 52.05 |
| 19 | [<a target="_blank" href="https://huggingface.co/maldv/Awqward2.5-32B-Instruct" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">maldv/Awqward2.5-32B-Instruct</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/maldv__Awqward2.5-32B-Instruct-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/maldv/Awqward2.5-32B-Instruct) | 46.75 | 32.8 | 82.55 | 57.21 | 62.31 | 12.08 | 13.87 | 52.48 |
| 20 | [<a target="_blank" href="https://huggingface.co/raphgg/test-2.5-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">raphgg/test-2.5-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/raphgg__test-2.5-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/raphgg/test-2.5-72B) | 46.74 | 72.7 | 84.37 | 62.15 | 41.09 | 18.57 | 20.52 | 53.74 |


[View Complete Online Leaderboard](https://chenjy16.github.io/modelrank_ai/)

## Domain-Specific Leaderboards

Domain-specific model leaderboards can be accessed via the following links:

- [Medical Domain Leaderboard](https://chenjy16.github.io/modelrank_ai/medical_leaderboard.html)
- [Legal Domain Leaderboard](https://chenjy16.github.io/modelrank_ai/legal_leaderboard.html)
- [Finance Domain Leaderboard](https://chenjy16.github.io/modelrank_ai/finance_leaderboard.html)

## ğŸ¥ Medical Domain Leaderboard

*Top 10 models shown. Last updated: 2025-04-07 06:36:11 UTC*

| Rank | Model | Avg Score | Params(B) | MMLU-PRO | BBH | GPQA |
| --- | --- | --- | --- | --- | --- | --- |
| 1 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-3.2-instruct-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-3.2-instruct-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-3.2-instruct-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-3.2-instruct-78b) | 57.87 | 78.0 | 70.03 | 62.61 | 20.36 |
| 2 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-3.1-instruct-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-3.1-instruct-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-3.1-instruct-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-3.1-instruct-78b) | 56.98 | 78.0 | 68.72 | 62.41 | 19.46 |
| 3 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.4-rys-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.4-rys-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b) | 56.06 | 78.0 | 66.69 | 62.16 | 20.36 |
| 4 | [<a target="_blank" href="https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">dfurman/CalmeRys-78B-Orpo-v0.1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/dfurman__CalmeRys-78B-Orpo-v0.1-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1) | 55.98 | 78.0 | 66.80 | 61.92 | 20.02 |
| 5 | [<a target="_blank" href="https://huggingface.co/newsbang/Homer-v1.0-Qwen2.5-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">newsbang/Homer-v1.0-Qwen2.5-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/newsbang__Homer-v1.0-Qwen2.5-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/newsbang/Homer-v1.0-Qwen2.5-72B) | 51.70 | 72.7 | 57.17 | 62.27 | 22.15 |
| 6 | [<a target="_blank" href="https://huggingface.co/Sakalti/ultiima-72B-v1.5" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Sakalti/ultiima-72B-v1.5</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Sakalti__ultiima-72B-v1.5-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Sakalti/ultiima-72B-v1.5) | 51.47 | 72.7 | 56.15 | 63.44 | 21.81 |
| 7 | [<a target="_blank" href="https://huggingface.co/JungZoona/T3Q-qwen2.5-14b-v1.0-e3" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">JungZoona/T3Q-qwen2.5-14b-v1.0-e3</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/JungZoona__T3Q-qwen2.5-14b-v1.0-e3-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/JungZoona/T3Q-qwen2.5-14b-v1.0-e3) | 51.23 | 14.8 | 54.27 | 65.47 | 22.26 |
| 8 | [<a target="_blank" href="https://huggingface.co/JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/JungZoona__T3Q-Qwen2.5-14B-Instruct-1M-e3-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3) | 51.23 | 0 | 54.27 | 65.47 | 22.26 |
| 9 | [<a target="_blank" href="https://huggingface.co/Sakalti/ultiima-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Sakalti/ultiima-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Sakalti__ultiima-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Sakalti/ultiima-72B) | 49.97 | 72.7 | 54.51 | 61.10 | 21.92 |
| 10 | [<a target="_blank" href="https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-72b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rombodawg/Rombos-LLM-V2.5-Qwen-72b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-72b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-72b) | 49.76 | 72.7 | 54.83 | 61.27 | 19.80 |

[View Full Medical Leaderboard](https://chenjy16.github.io/modelrank_ai/medical_leaderboard.html)

## âš–ï¸ Legal Domain Leaderboard

*Top 10 models shown. Last updated: 2025-04-07 06:36:11 UTC*

| Rank | Model | Avg Score | Params(B) | MMLU-PRO | BBH |
| --- | --- | --- | --- | --- | --- |
| 1 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-3.2-instruct-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-3.2-instruct-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-3.2-instruct-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-3.2-instruct-78b) | 67.06 | 78.0 | 70.03 | 62.61 |
| 2 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-3.1-instruct-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-3.1-instruct-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-3.1-instruct-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-3.1-instruct-78b) | 66.20 | 78.0 | 68.72 | 62.41 |
| 3 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.4-rys-78b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.4-rys-78b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b) | 64.88 | 78.0 | 66.69 | 62.16 |
| 4 | [<a target="_blank" href="https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">dfurman/CalmeRys-78B-Orpo-v0.1</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/dfurman__CalmeRys-78B-Orpo-v0.1-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1) | 64.85 | 78.0 | 66.80 | 61.92 |
| 5 | [<a target="_blank" href="https://huggingface.co/newsbang/Homer-v1.0-Qwen2.5-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">newsbang/Homer-v1.0-Qwen2.5-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/newsbang__Homer-v1.0-Qwen2.5-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/newsbang/Homer-v1.0-Qwen2.5-72B) | 59.21 | 72.7 | 57.17 | 62.27 |
| 6 | [<a target="_blank" href="https://huggingface.co/Sakalti/ultiima-72B-v1.5" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Sakalti/ultiima-72B-v1.5</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Sakalti__ultiima-72B-v1.5-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Sakalti/ultiima-72B-v1.5) | 59.07 | 72.7 | 56.15 | 63.44 |
| 7 | [<a target="_blank" href="https://huggingface.co/JungZoona/T3Q-qwen2.5-14b-v1.0-e3" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">JungZoona/T3Q-qwen2.5-14b-v1.0-e3</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/JungZoona__T3Q-qwen2.5-14b-v1.0-e3-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/JungZoona/T3Q-qwen2.5-14b-v1.0-e3) | 58.75 | 14.8 | 54.27 | 65.47 |
| 8 | [<a target="_blank" href="https://huggingface.co/JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/JungZoona__T3Q-Qwen2.5-14B-Instruct-1M-e3-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/JungZoona/T3Q-Qwen2.5-14B-Instruct-1M-e3) | 58.75 | 0 | 54.27 | 65.47 |
| 9 | [<a target="_blank" href="https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-72b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">rombodawg/Rombos-LLM-V2.5-Qwen-72b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-72b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-72b) | 57.41 | 72.7 | 54.83 | 61.27 |
| 10 | [<a target="_blank" href="https://huggingface.co/Sakalti/ultiima-72B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Sakalti/ultiima-72B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Sakalti__ultiima-72B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Sakalti/ultiima-72B) | 57.15 | 72.7 | 54.51 | 61.10 |

[View Full Legal Leaderboard](https://chenjy16.github.io/modelrank_ai/legal_leaderboard.html)

## ğŸ’° Finance Domain Leaderboard

*Top 10 models shown. Last updated: 2025-04-07 06:36:11 UTC*

| Rank | Model | Avg Score | Params(B) | MATH Lvl 5 | MMLU-PRO | BBH |
| --- | --- | --- | --- | --- | --- | --- |
| 1 | [<a target="_blank" href="https://huggingface.co/maldv/Awqward2.5-32B-Instruct" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">maldv/Awqward2.5-32B-Instruct</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/maldv__Awqward2.5-32B-Instruct-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/maldv/Awqward2.5-32B-Instruct) | 58.34 | 32.8 | 62.31 | 52.48 | 57.21 |
| 2 | [<a target="_blank" href="https://huggingface.co/Qwen/Qwen2.5-32B-Instruct" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Qwen/Qwen2.5-32B-Instruct</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-32B-Instruct-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Qwen/Qwen2.5-32B-Instruct) | 58.12 | 32.8 | 62.54 | 51.85 | 56.49 |
| 3 | [<a target="_blank" href="https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V6-32B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Saxo/Linkbricks-Horizon-AI-Avengers-V6-32B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Saxo__Linkbricks-Horizon-AI-Avengers-V6-32B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V6-32B) | 57.93 | 32.8 | 62.24 | 51.92 | 56.19 |
| 4 | [<a target="_blank" href="https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V3-32B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Saxo/Linkbricks-Horizon-AI-Avengers-V3-32B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Saxo__Linkbricks-Horizon-AI-Avengers-V3-32B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V3-32B) | 57.74 | 32.8 | 61.78 | 51.82 | 56.53 |
| 5 | [<a target="_blank" href="https://huggingface.co/Qwen/Qwen2.5-72B-Instruct" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Qwen/Qwen2.5-72B-Instruct</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-72B-Instruct-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) | 57.70 | 72.7 | 59.82 | 51.40 | 61.87 |
| 6 | [<a target="_blank" href="https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/Saxo__Linkbricks-Horizon-AI-Avengers-V1-32B-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B) | 57.64 | 32.8 | 60.27 | 53.25 | 57.63 |
| 7 | [<a target="_blank" href="https://huggingface.co/ehristoforu/qwen2.5-test-32b-it" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ehristoforu/qwen2.5-test-32b-it</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/ehristoforu__qwen2.5-test-32b-it-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/ehristoforu/qwen2.5-test-32b-it) | 57.41 | 32.8 | 59.74 | 52.95 | 58.28 |
| 8 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2.5-72b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.1-qwen2.5-72b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-qwen2.5-72b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2.5-72b) | 57.30 | 72.7 | 59.14 | 51.32 | 61.66 |
| 9 | [<a target="_blank" href="https://huggingface.co/huihui-ai/Qwen2.5-72B-Instruct-abliterated" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">huihui-ai/Qwen2.5-72B-Instruct-abliterated</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/huihui-ai__Qwen2.5-72B-Instruct-abliterated-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/huihui-ai/Qwen2.5-72B-Instruct-abliterated) | 57.28 | 72.7 | 60.12 | 50.41 | 60.49 |
| 10 | [<a target="_blank" href="https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2.5-72b" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">MaziyarPanahi/calme-2.2-qwen2.5-72b</a>  <a target="_blank" href="https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-qwen2.5-72b-details" style="color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;">ğŸ“‘</a>](https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2.5-72b) | 57.21 | 72.7 | 58.91 | 51.31 | 61.80 |

[View Full Finance Leaderboard](https://chenjy16.github.io/modelrank_ai/finance_leaderboard.html)

## Complete Data

The complete leaderboard data can be viewed through the following methods:

- [Online Complete Leaderboard](https://chenjy16.github.io/modelrank_ai/)
- [JSON Format Data](https://chenjy16.github.io/modelrank_ai/leaderboard.json)
- [CSV Format Data](https://chenjy16.github.io/modelrank_ai/leaderboard.csv)

## Evaluation Metrics Explanation

The leaderboard includes the following main evaluation metrics:

- **Average â¬†ï¸**: Average score of all evaluations
- **IFEval**: Instruction following capability evaluation
- **BBH**: Big-Bench Hard benchmark for large language models
- **MATH Lvl 5**: Mathematical problem-solving capability evaluation
- **GPQA**: General Physics Question Answering evaluation
- **MUSR**: Multi-step reasoning evaluation
- **MMLU-PRO**: Massive Multitask Language Understanding Professional version evaluation

## Local Development

### Prerequisites

- Python 3.10+
- HuggingFace API token

### Installation Steps

1. Clone the repository
   ```bash
   git clone https://github.com/chenjy16/modelrank_ai.git
   cd modelrank_ai
   ```




## License

This project is open-sourced under the MIT License.


## ğŸŒ Domain-Specific Leaderboards

Explore leaderboards focused on specific professional areas:

- [ğŸ¥ Medical Domain Leaderboard](https://chenjy16.github.io/modelrank_ai/medical_leaderboard.html)
- [âš–ï¸ Legal Domain Leaderboard](https://chenjy16.github.io/modelrank_ai/legal_leaderboard.html)
- [ğŸ’° Finance Domain Leaderboard](https://chenjy16.github.io/modelrank_ai/finance_leaderboard.html)

## Data Source

Data is sourced from HuggingFace.

